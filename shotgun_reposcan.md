{"contexts":{"ShotgunApp":{"description":"A desktop tool that packages an entire project's source code into a single, large text payload for use with Large Language Models (LLMs). It aims to solve the problem of providing complete context to AI assistants for tasks like large-scale refactoring, bug fixing, and documentation generation.","c4_level":"Context"}},"containers":{"WailsApp":{"description":"The main application container, a cross-platform desktop application built with the Wails framework. It combines a Go backend and a Vue.js frontend into a single executable. This container is responsible for providing the user interface, handling file operations, and generating the 'context payload' for the LLM.","technology_stack":["Go (Backend)","Vue.js v3 (Frontend)","Wails v2 (Framework)","embed.FS (for bundling frontend assets)"],"responsibilities":["Providing a graphical user interface (GUI) for project selection and file management.","Scanning the file system to build a project tree.","Applying ignore rules (.gitignore, custom rules).","Generating a single text file ('Context Payload') from the selected project files.","Interacting with the operating system's clipboard.","Watching for changes in the project's file system."],"communication_mechanisms":["Interaction between Go and Vue.js is handled via JavaScript bindings automatically generated by Wails. Go methods bound in `main.go` can be called directly from JavaScript as asynchronous functions. Wails also provides an event system for asynchronous data push from the backend to the frontend."],"c4_level":"Container"}},"domain_glossary":{"Shotgun":{"description":"The name of the application, used as a metaphor for a 'whole-repository blast' - packaging the entire codebase into a single payload for an LLM.","c4_level":"Context"},"LLM":{"description":"Large Language Model. The primary consumer of the output generated by the Shotgun App. Examples include ChatGPT, Gemini, etc.","c4_level":"Context"},"Context Payload":{"description":"The structured text output generated by the application, containing a file tree representation and the contents of all included files, formatted for easy parsing by an LLM.","c4_level":"Context"},"Wails":{"description":"A framework for building cross-platform desktop applications with a Go backend and a web-based frontend. It handles the communication between Go and JavaScript.","c4_level":"Context"}},"deployment_topology":{"desktop_app":{"description":"The system is a single, cross-platform (Windows, macOS, Linux) desktop application.","type":"Desktop Application","technology_stack":["Go (Backend)","Vue.js v3 (Frontend)","Wails v2 (Framework)"],"communication":"The Go backend and Vue.js frontend communicate via Wails bindings, which bridge Go functions to JavaScript calls.","c4_level":"Container"},"development_environment":{"description":"The development and build environment requires Go (>=1.20), Node.js (LTS), and the Wails CLI tool.","c4_level":"Container"}},"data_schema":{"FileNode":{"description":"Represents a single file or directory in the project tree. This structure is serialized to JSON and sent to the frontend to render the file explorer.","fields":{"name":"string // The base name of the file or directory.","path":"string // The full, absolute path on the file system.","relPath":"string // The path relative to the project root.","isDir":"bool // True if the node is a directory.","children":"array[FileNode] // A list of child nodes, present if isDir is true.","isGitignored":"bool // True if the path is matched by a .gitignore rule.","isCustomIgnored":"bool // True if the path is matched by a custom user-defined ignore rule."},"c4_level":"Component"},"AppSettings":{"description":"Represents the user's configuration, which is persisted to `settings.json`.","fields":{"customIgnoreRules":"string // A multi-line string containing glob patterns for custom file/directory ignoring.","customPromptRules":"string // A string containing user-defined rules or instructions to be included in LLM prompts."},"c4_level":"Component"},"PromptHistoryItem":{"description":"Представляет одну запись в истории взаимодействий с LLM.","c4_level":"Component","fields":{"ID":"string // Уникальный идентификатор, основанный на временной метке (UnixNano).","Timestamp":"time.Time // Время создания записи.","UserTask":"string // Описание задачи, введенное пользователем.","ConstructedPrompt":"string // Полный промпт, отправленный в LLM.","Response":"string // Ответ, полученный от LLM.","APICall":"string // (Опционально) Детали вызова API для отладки."}}},"components":{"GoBackend":{"description":"The core backend logic of the Shotgun App, written in Go. It runs within the Wails container and is responsible for all file system operations, context generation, and configuration management. It exposes its methods to the Vue.js frontend via Wails bindings.","technology_stack":["Go","Wails v2","fsnotify","go-gitignore"],"responsibilities":["Providing an API for the frontend to interact with the file system.","Scanning project directories and building a file tree structure.","Applying .gitignore and custom ignore rules to filter files.","Asynchronously generating a large text payload ('Context Payload') from selected files.","Watching the file system for changes and notifying the frontend.","Managing user settings (custom ignore/prompt rules) via a JSON config file.","Exposing a comprehensive API to the frontend via Wails bindings for file operations, settings management, and LLM interactions.","Emitting events to the frontend for asynchronous updates, such as file changes and progress of long-running tasks.","Connecting to third-party Large Language Models, supporting providers like OpenAI, OpenRouter, and Gemini, with specialized handling for different model families (e.g., GPT-5).","Implementing an 'Auto-Context' feature that queries a configured LLM to suggest relevant project files based on a user's task description."],"c4_level":"Component","api_surface":{"description":"The Go backend exposes its functionality to the Vue.js frontend through two primary mechanisms provided by the Wails framework: direct method bindings and an event system.","wails_bindings":{"description":"Public methods of the `App` struct are bound at startup and can be called directly from JavaScript as asynchronous functions. This forms the primary request-response API.","methods":[{"name":"SelectDirectory","signature":"() (string, error)","description":"Opens a native OS dialog for the user to select a project directory."},{"name":"ListFiles","signature":"(dirPath string) ([]*FileNode, error)","description":"Scans the specified directory, builds a file tree, and applies .gitignore and custom ignore rules."},{"name":"RequestShotgunContextGeneration","signature":"(rootDir string, excludedPaths []string)","description":"Starts an asynchronous job to generate the 'Context Payload' from the files in the given root directory, respecting exclusions. Progress and results are sent via Wails events."},{"name":"RequestAutoContextSelection","signature":"(rootDir string, excludedPaths []string, userTask string) ([]string, error)","description":"Uses a configured LLM to analyze the project's file tree and user's task to suggest a relevant set of files for the context."},{"name":"StartFileWatcher","signature":"(rootDirPath string) error","description":"Starts a file system watcher for the specified directory to detect changes."},{"name":"StopFileWatcher","signature":"() error","description":"Stops the active file system watcher."},{"name":"GetCustomIgnoreRules","signature":"() string","description":"Returns the user's custom ignore rules from settings."},{"name":"SetCustomIgnoreRules","signature":"(rules string) error","description":"Updates and persists the user's custom ignore rules."},{"name":"GetCustomPromptRules","signature":"() string","description":"Returns the user's custom prompt rules from settings."},{"name":"SetCustomPromptRules","signature":"(rules string) error","description":"Updates and persists the user's custom prompt rules."},{"name":"SetUseGitignore","signature":"(enabled bool) error","description":"Enables or disables the use of .gitignore files for filtering."},{"name":"SetUseCustomIgnore","signature":"(enabled bool) error","description":"Enables or disables the use of custom ignore rules for filtering."},{"name":"SaveRepoScan","signature":"(rootDir string, content string) error","description":"Saves the content of a repository scan to 'shotgun_reposcan.md' in the project root."},{"name":"LoadRepoScan","signature":"(rootDir string) (string, error)","description":"Loads the content of 'shotgun_reposcan.md' from the project root."},{"name":"GetAutoContextButtonTexture","signature":"() string","description":"Generates and returns a data URL for a procedural gradient texture used in the UI."},{"name":"ExecuteLLMPrompt","signature":"(userTask, finalPrompt string) (PromptHistoryItem, error)","description":"Sends a prompt to the configured LLM, waits for the response, and adds the exchange to the prompt history."},{"name":"GetPromptHistory","signature":"() []PromptHistoryItem","description":"Retrieves the list of all past prompt interactions."},{"name":"ClearPromptHistory","signature":"() error","description":"Deletes all entries from the prompt history."},{"name":"GetLlmSettings","signature":"() LLMSettings","description":"Retrieves the current LLM configuration (provider, model, keys, etc.)."},{"name":"SetLlmApiKey","signature":"(providerName, apiKey string) error","description":"Sets and persists the API key for a specific LLM provider."},{"name":"SetLlmProvider","signature":"(providerName string) error","description":"Sets the active LLM provider."},{"name":"SetLlmModel","signature":"(providerName, model string) error","description":"Sets the model to be used for a specific LLM provider."},{"name":"SetLlmBaseURL","signature":"(baseURL string) error","description":"Sets a custom base URL for API requests, typically for proxy or self-hosted models."},{"name":"ListLlmModels","signature":"(providerName string) ([]provider.ModelInfo, error)","description":"Returns a list of available models for a given provider."},{"name":"SplitShotgunDiff","signature":"(gitDiffText string, approxLineLimit int) ([]string, error)","description":"Splits a large git diff into smaller chunks, attempting to break between files or hunks to stay within a line limit."}]},"wails_events":{"description":"The Go backend can push data asynchronously to the frontend using a pub/sub event system. The frontend listens for these events to update its state.","events":[{"name":"shotgunContextGenerated","payload":"string // The full context payload.","description":"Sent when the context payload generation is successfully completed."},{"name":"shotgunContextError","payload":"string // An error message.","description":"Sent when an error occurs during context generation, including cancellation."},{"name":"shotgunContextGenerationProgress","payload":"map[string]int // {current: int, total: int}","description":"Sent periodically during context generation to update a progress bar."},{"name":"projectFilesChanged","payload":"string // The root directory path.","description":"Sent by the file watcher when a change is detected in the project directory, signaling the frontend to refresh the file tree."},{"name":"autoContextError","payload":"string // An error message.","description":"Sent when an error occurs during the auto-context selection process."}]},"c4_level":"Component"},"subcomponents":{"AutoContextService":{"description":"An internal service responsible for using a Large Language Model (LLM) to automatically suggest a set of relevant files based on a user's task description. It is invoked by the `RequestAutoContextSelection` API method.","c4_level":"Component","responsibilities":["Building a string representation of the project's file tree, respecting user exclusions and size limits.","Loading a prompt template from an embedded file (`design/prompts/contextPreparation.md`).","Formatting a prompt for the LLM that includes the file tree and the user's task.","Parsing a JSON response from the LLM, which is expected to contain a list of file paths.","Normalizing and validating the file paths returned by the LLM against the local file system, and expanding any returned directories into a list of files."]},"HistoryManagement":{"description":"Отвечает за сохранение и извлечение истории взаимодействий с LLM. Компонент управляет списком записей `PromptHistoryItem` как в памяти, так и на диске, сохраняя их в файл `prompt_history.json` в каталоге конфигурации пользователя. Новые записи добавляются в начало списка. Сохранение на диск происходит асинхронно, чтобы не блокировать пользовательский интерфейс.","c4_level":"Component","responsibilities":["Хранение истории взаимодействий с LLM в памяти.","Загрузка истории из файла `prompt_history.json` при запуске приложения.","Сохранение истории в файл `prompt_history.json` при добавлении или очистке записей.","Предоставление API для добавления, получения и очистки истории."],"data_structures":["PromptHistoryItem"],"storage_mechanism":"JSON file (`prompt_history.json`)"}}},"VueFrontend":{"description":"The application's user interface, built as a Single-Page Application (SPA) with Vue.js 3. It runs inside a Wails webview and is responsible for all user interaction logic. The frontend communicates with the Go backend via Wails bindings to perform file operations and other core tasks.","c4_level":"Component","technology_stack":["Vue.js v3 (Composition API)","Vite","TailwindCSS","Wails v2 JavaScript runtime & bindings"],"responsibilities":["Providing a multi-step user interface for the main workflow (Prepare Context -> Compose Prompt -> Execute -> Apply Patch).","Calling the Go backend via Wails bindings to perform file system operations (e.g., opening a directory dialog, listing files).","Displaying the project's file structure in an interactive tree, based on data received from the backend.","Allowing users to include/exclude files and folders, and communicating these choices to the backend for context generation.","Displaying the large 'Context Payload' generated by the backend.","Providing an interface to manage application settings (e.g., LLM provider, API keys, custom ignore rules) by calling backend methods.","Listening for asynchronous events from the backend (e.g., file system changes, context generation progress) using the Wails event system to provide real-time UI updates."],"api_surface":{"description":"The Vue.js frontend interacts with the Go backend through two primary mechanisms provided by the Wails framework: direct method bindings and an event system. All backend calls are asynchronous and return JavaScript Promises.","c4_level":"Component","wails_bindings":{"description":"The frontend calls Go methods exposed on the global `window.go.main.App` object. These functions are automatically generated by Wails and provide a typed interface (via TypeScript definitions) to the backend's `App` struct. This is the primary mechanism for request-response interactions.","examples":[{"name":"SelectDirectory","usage":"Calls the backend to open a native OS directory selection dialog."},{"name":"ListFiles","usage":"Requests the file tree for a given directory path."},{"name":"RequestShotgunContextGeneration","usage":"Initiates the asynchronous generation of the context payload, passing the list of excluded files."},{"name":"GetLlmSettings","usage":"Retrieves the current LLM configuration from the backend."},{"name":"SetLlmApiKey","usage":"Sends an updated API key to the backend to be persisted."}]},"wails_events":{"description":"The frontend uses the Wails runtime API (`window.runtime.EventsOn`) to subscribe to events emitted by the Go backend. This allows the backend to push data and notifications to the UI asynchronously, which is used for progress updates and real-time notifications.","examples":[{"name":"shotgunContextGenerated","usage":"Listens for this event to receive the final context payload when generation is complete."},{"name":"shotgunContextGenerationProgress","usage":"Listens for progress updates during context generation to update the UI (e.g., a progress bar)."},{"name":"projectFilesChanged","usage":"Listens for this event to know when to refresh the file tree after the file watcher detects a change."},{"name":"shotgunContextError","usage":"Listens for errors that occur during backend processing."}]}},"subcomponents":{"MainLayout":{"description":"The top-level orchestrator component for the main application UI. It manages the overall page structure (sidebar, central panel, console), holds the primary UI state (file tree, project path, current step), and handles most of the communication with the Go backend via Wails bindings and events.","c4_level":"Component","technology_stack":["Vue.js 3 (Composition API)"],"responsibilities":["Arranges core UI elements: LeftSidebar, CentralPanel, and BottomConsole.","Manages global UI state such as the current project, file tree data, and workflow step.","Fetches data from and sends commands to the Go backend.","Listens for asynchronous events from the backend to update the UI in real-time.","Orchestrates communication between child components via props and events."]},"LeftSidebar":{"description":"A component located on the left side of the UI, responsible for project selection, file tree display, and configuration of file filtering rules (.gitignore, custom rules). It contains the FileTree component.","c4_level":"Component","technology_stack":["Vue.js 3"],"responsibilities":["Providing a button to trigger the project folder selection dialog.","Displaying the currently selected project path.","Offering controls (checkboxes) to enable or disable filtering based on .gitignore and custom ignore rules.","Hosting the FileTree component to display the project structure.","Displaying a vertical navigation menu for the main application steps."]},"CentralPanel":{"description":"The main content area of the application. It acts as a router, dynamically displaying the content for the current step of the user workflow (e.g., Step 1: Prepare Context, Step 2: Compose Prompt).","c4_level":"Component","technology_stack":["Vue.js 3"],"responsibilities":["Conditionally rendering the appropriate 'Step' component based on the application's current state.","Passing necessary data (e.g., generated context, project info) from the parent MainLayout down to the active Step component.","Bubbling up user actions and data from the Step components to the MainLayout."]},"BottomConsole":{"description":"A resizable panel at the bottom of the screen that displays timestamped application logs. It provides users with real-time feedback on background processes, errors, and general application events.","c4_level":"Component","technology_stack":["Vue.js 3"],"responsibilities":["Displaying a list of log messages received from the parent component.","Color-coding logs based on severity (info, error, success, warn).","Automatically scrolling to show the most recent log message.","Allowing the user to resize its height via a drag handle."]},"FileTree":{"description":"A recursive component that renders the project's file and directory structure in an interactive tree view. It is a core part of the LeftSidebar.","c4_level":"Component","technology_stack":["Vue.js 3"],"responsibilities":["Displaying files and directories hierarchically with proper indentation.","Allowing users to expand and collapse directories.","Providing a checkbox for each item to include or exclude it from the context generation.","Emitting events to the parent component when an item's exclusion state is changed.","Visually indicating which files are excluded (e.g., strikethrough text)."]},"CustomRulesModal":{"description":"A reusable modal dialog component for editing multi-line text. It is used for managing both custom `.gitignore`-style ignore patterns and custom instructions (prompt rules) to be included in the LLM prompt. It operates as a controlled component, receiving initial values via props and emitting 'save' or 'cancel' events to its parent, which is responsible for backend communication.","c4_level":"Component","technology_stack":["Vue.js 3"],"responsibilities":["Providing a textarea for editing text-based rules.","Displaying different descriptive text based on whether it's editing 'ignore' or 'prompt' rules.","Emitting the updated text to a parent component upon saving.","Notifying the parent component upon cancellation."]},"LlmSettingsModal":{"description":"A comprehensive modal dialog for configuring all settings related to Large Language Models (LLMs). It allows the user to select a provider (OpenAI, OpenRouter, Gemini), manage API keys, set a custom base URL for API endpoints, and select a specific model. This component interacts directly and heavily with the Go backend via Wails bindings to fetch data and persist settings.","c4_level":"Component","technology_stack":["Vue.js 3"],"responsibilities":["Managing the selection of the active LLM provider.","Handling input and persistence of API keys for different providers.","Allowing configuration of a custom API base URL.","Fetching a list of available models for the selected provider by calling the backend.","Saving all LLM settings by calling multiple backend methods.","Displaying loading states and error messages from backend interactions."],"backend_interactions":["ListLlmModels","SetLlmApiKey","SetLlmBaseURL","SetLlmModel","SetLlmProvider"]},"RepoScanModal":{"description":"A modal dialog for viewing and editing the 'Repo Scan' content. This content is a user-provided summary or analysis of the repository that is attached to certain LLM prompts to provide better context. The component is a controlled component that emits the saved content to its parent. It also uses the Wails runtime to open external web links.","c4_level":"Component","technology_stack":["Vue.js 3"],"responsibilities":["Providing a textarea for editing the repo scan text.","Emitting the updated text to a parent component upon saving.","Opening an external URL in the user's default browser via the Wails runtime."]},"MainWorkflow":{"description":"Инкапсулирует основной многошаговый пользовательский рабочий процесс приложения, который направляет пользователя от подготовки контекста до выполнения промпта и просмотра результатов. Этот рабочий процесс визуально управляется компонентом HorizontalStepper и состоит из нескольких 'Step' компонентов, каждый из которых отвечает за определенный этап.","c4_level":"Component","responsibilities":["Предоставление четкого, пошагового пользовательского интерфейса для взаимодействия с LLM.","Управление состоянием и данными на каждом этапе рабочего процесса.","Оркестрация взаимодействия между различными этапами."],"subcomponents":{"HorizontalStepper":{"description":"Визуальный компонент, который отображает шаги основного рабочего процесса (например, 'Prepare Context', 'Compose Prompt'). Он показывает текущий шаг, завершенные шаги и обеспечивает навигацию между ними. Логика навигации (например, предотвращение перехода к будущим незавершенным шагам) встроена в компонент.","c4_level":"Component"},"Step1PrepareContext":{"description":"Первый шаг рабочего процесса, на котором пользователь определяет свою задачу и подготавливает контекст проекта для LLM. Этот компонент фокусируется на сборе входных данных.","c4_level":"Component","responsibilities":["Предоставление текстового поля для ввода пользователем задачи для ИИ.","Отображение прогресса генерации контекста, который инициируется родительским компонентом.","Отображение сгенерированного контекста проекта в текстовом поле только для чтения с возможностью копирования.","Управление функцией 'Auto context', которая использует LLM для автоматического выбора релевантных файлов на основе задачи пользователя.","Управление 'Repo Scan' (сводка репозитория), включая его загрузку, редактирование через модальное окно и сохранение через бэкенд."],"backend_interactions":["LoadRepoScan","SaveRepoScan"]},"Step2ComposePrompt":{"description":"Второй шаг, на котором необработанные входные данные из Шага 1 (задача, контекст) объединяются с шаблонами и правилами для создания окончательного, готового к отправке промпта.","c4_level":"Component","responsibilities":["Отображение и разрешение редактирования задачи пользователя и пользовательских правил.","Предоставление выбора шаблонов промптов (например, Dev, Architect, Find Bug).","Автоматическое составление 'Финального промпта' путем подстановки задачи, правил и контекста в выбранный шаблон.","Отображение приблизительного количества токенов в финальном промпте.","Инициирование выполнения промпта путем вызова бэкенд-функции.","Отображение ответа от LLM в модальном окне после выполнения."],"backend_interactions":["GetCustomPromptRules","SetCustomPromptRules","ExecuteLLMPrompt"]},"Step3ExecutePrompt":{"description":"Третий шаг, который служит для просмотра истории взаимодействий с LLM. Он не инициирует новых действий, а предоставляет интерфейс для анализа прошлых запросов и ответов.","c4_level":"Component","responsibilities":["Отображение списка прошлых выполненных промптов, отсортированных по времени.","При выборе элемента истории, отображение деталей в виде разделенного экрана: 'Raw Request' (отправленный промпт) и 'Response' (ответ LLM).","Предоставление возможности просмотреть детали вызова API к LLM в модальном окне для отладки.","Предоставление функций для обновления и полной очистки истории промптов."],"backend_interactions":["GetPromptHistory","ClearPromptHistory"]}}}}}},"external_integrations":{"OpenAI":{"description":"Integration with OpenAI's Large Language Models. It uses the official `https://api.openai.com/v1` endpoint. For standard models, it leverages the `langchaingo` library. For the newer GPT-5 family of models, it uses a custom HTTP client to call the `/responses` API with specific reasoning and verbosity controls, identified by the `OpenAI-Beta: responses=v1` header.","authentication_method":"API Key (Bearer Token)","supported_models":[{"name":"gpt-5.1","description":"Latest GPT-5.1 flagship for complex reasoning and coding tasks"},{"name":"gpt-5","description":"Previous GPT-5 flagship reasoning model"},{"name":"gpt-5-mini","description":"Cost-optimized GPT-5 mini model"},{"name":"gpt-5-nano","description":"High-throughput GPT-5 nano model"},{"name":"gpt-4o-mini","description":"Latest GPT-4o mini for general reasoning"},{"name":"gpt-4.1-mini","description":"GPT-4.1 mini tier"},{"name":"o4-mini","description":"Reasoning optimized 04-mini"},{"name":"gpt-4o","description":"Full GPT-4o"},{"name":"gpt-4.1","description":"Full GPT-4.1"}],"c4_level":"Component"},"OpenRouter":{"description":"Integration with OpenRouter, a service that provides access to a variety of LLMs through an OpenAI-compatible API. The default endpoint is `https://openrouter.ai/api/v1`. Similar to the direct OpenAI integration, it uses a standard client for most models but switches to a custom HTTP client for GPT-5 family models, calling the `/chat/completions` endpoint with specific reasoning parameters.","authentication_method":"API Key (Bearer Token)","supported_models":[{"name":"openai/gpt-5","description":"GPT-5 family routed via OpenRouter"},{"name":"anthropic/claude-3.5-sonnet","description":"Claude 3.5 Sonnet via OpenRouter"},{"name":"google/gemini-pro-1.5","description":"Gemini Pro 1.5 proxied through OpenRouter"},{"name":"openai/gpt-4o-mini","description":"GPT-4o mini from OpenRouter catalog"},{"name":"meta-llama/llama-3.1-70b-instruct","description":"Llama 3.1 70B Instruct via OpenRouter"}],"c4_level":"Component"},"Gemini":{"description":"Integration with Google's Gemini models via the `langchaingo` Go library. It connects to the Google AI API to perform text generation.","authentication_method":"API Key","supported_models":[{"name":"gemini-2.5-pro","description":"Most capable Gemini 2.5 Pro"},{"name":"gemini-2.5-flash","description":"Flash"}],"c4_level":"Component"}},"testing_strategy":{"c4_level":"Container","summary":"Based on a full repository scan, there is no evidence of a formal, automated testing strategy. No unit, integration, or end-to-end test files (e.g., `*_test.go`, `*.spec.js`, `*.test.ts`) or testing framework configurations were found. The file `test.txt` is a stray artifact and not part of a testing process.","methodology":"Manual Testing. It is inferred that testing is performed manually by developers or users during the development cycle."},"configuration":{"c4_level":"Container","file_filtering":{"description":"The application filters files for context generation using multiple layers of rules. It respects `.gitignore` files found in the project directory, applies a set of default global ignore patterns defined in `ignore.glob`, and allows the user to provide their own custom ignore rules through the UI.","default_ignore_patterns_file":"ignore.glob"},"frontend_build":{"description":"The frontend is built using Vite. PostCSS is used for CSS processing, specifically with TailwindCSS for styling and Autoprefixer for browser compatibility. The configuration is largely standard for a Vue.js project.","tools":["Vite","PostCSS","TailwindCSS","Autoprefixer"]},"llm_interaction":{"description":"The application's interactions with Large Language Models are heavily configured through a series of prompt templates stored as Markdown files in the `design/prompts/` directory. These templates define the roles, goals, instructions, and output formats for various AI-driven features, such as automatic context selection, code generation, bug analysis, and architectural planning. The presence of multiple 'old' prompt files suggests an iterative development process for these prompts.","prompt_template_directory":"design/prompts/"}},"security_posture":{"c4_level":"Context","licensing":{"description":"The software is distributed under a custom 'SHOTGUN COMMUNITY LICENSE AGREEMENT' as defined in `LICENSE.md`. This is not a standard OSI-approved open-source license. It restricts commercial use by individuals or entities with an annual gross revenue (or funding) exceeding $1,000,000 USD, who are required to purchase a separate commercial license. This licensing model is the most significant aspect of the project's security and compliance posture.","license_file":"LICENSE.md","type":"Custom (Community License with Commercial Restrictions)"}}}