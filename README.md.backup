![](https://github.com/user-attachments/assets/058bf4a2-9f81-406c-96ea-795cd4eaf118)

**Tired of Cursor cutting off context, missing your files and folders, and spitting out empty responses?**

Save your context with Shotgun!
â†’ Prepare a truly GIGANTIC prompt
â†’ Paste it into **Google AI Studio** and receive a massive patch for your code. 25 free queries per day!
â†’ Drop that patch into Cursor or Windsurf and apply the entire diff in a single request.

**That means you get 25 huge, fully coherent patches per day for your codebaseâ€”absolutely free, thanks to complete context transfer.**

Perfect for dynamically-typed languages:

Python
JavaScript

# Shotgun App

_Oneâ€‘click codebase "blast" for Largeâ€‘Languageâ€‘Model workflows._

---

## 1. What Shotgun Does

Shotgun is a tiny desktop tool that **explodes an entire project into a single,
wellâ€‘structured text payload** designed for AI assistants.
Think of it as a rapidâ€‘fire alternative to copyâ€‘pasting dozens of files by hand:

- **Select a folder â†’ get an instant tree + file dump**
  in a predictable delimiter format (`*#*#*...*#*#*begin â€¦ *#*#*end*#*#*`).
- **Tick checkâ€‘boxes to exclude noise** (logs, build artifacts, `node_modules`, â€¦).
- **Paste the result into ChatGPT, Gemini 2.5, Cursor, etc.**
  to ask for multiâ€‘file edits, refactors, bug fixes, reviews, or documentation.
- **Receive a diffâ€‘style reply** and apply changes with your favourite patch tool.

Shotgun trades surgical, singleâ€‘file prompts for a **"wholeâ€‘repository blast"** â€“
hence the name.

---

## 2. Why You Might Need It

| Scenario                       | Pain Point                                     | Shotgun Benefit                                            |
| ------------------------------ | ---------------------------------------------- | ---------------------------------------------------------- |
| **Bulk bug fixing**            | "Please fix X across 12 files."                | Generates a complete snapshot so the LLM sees all usages.  |
| **Largeâ€‘scale refactor**       | IDE refactors miss edge cases.                 | LLM gets full context and returns a patch set.             |
| **Onâ€‘boarding review**         | New joiner must understand legacy code.        | Produce a single, searchable text file to discuss in chat. |
| **Doc generation**             | Want docs/tests for every exported symbol.     | LLM can iterate over full source without extra API calls.  |
| **Cursor / CodePilot prompts** | Tools accept pasted context but no filesystem. | Shotgun bridges the gap.                                   |

---

## 3. Key Features

- âš¡ **Fast tree scan** (Go + Wails backend) â€“ thousands of files in milliseconds.
- âœ… **Interactive exclude list** â€“ skip folders, temporary files, or secrets.
- ğŸ“ **Deterministic delimiters** â€“ easy for LLMs to parse and for you to split.
- ğŸ”„ **Reâ€‘generate anytime** â€“ tweak the excludes and hit _Shotgun_ again.
- ğŸª¶ **Lightweight** â€“ no DB, no cloud; a single native executable plus a Vue UI.
- ğŸ–¥ï¸ **Crossâ€‘platform** â€“ Windows, macOS, Linux.

---

## 4. How It Works

(This describes the UI flow. The core `GenerateShotgunOutput` Go function remains the primary backend logic for creating the text payload based on the selected root and exclusions.)

1. **Step 1: Prepare Context**
    - User selects a project folder.
    - The file tree is displayed in the `LeftSidebar`.
    - User can mark files/folders for exclusion.
    - The application automatically (or via a button) triggers context generation in Go (`GenerateShotgunOutput`).
    - The resulting context (tree + file contents) is prepared for the next step.
2. **Step 2: Compose Prompt**
    - The user writes the main task for the AI, selects a prompt template, and can add custom rules.
    - The application assembles the full initial prompt for the AI.
3. **Step 3: Chat with AI**
    - The application connects to the Google AI API using a user-provided key.
    - The composed prompt from Step 2 is sent as the initial message.
    - The user can chat with the AI to refine the output, which is streamed back in real-time.
    - Once satisfied, the user finalizes the chat, and the last AI response is used as the final prompt for the next step.
4. **Step 4: Apply Patch with Cursor**
    - Shotgun checks for the Cursor CLI (`cursor-agent`) and offers to install it automatically if it is missing.
    - The final, refined prompt from the chat is executed using `cursor-agent` against the project directory.
    - The output from the CLI is displayed.

---

## 5. Installation

### 5.1. Prerequisites

- **Go â‰¥ 1.20** `go version`
- **Node.js LTS** `node -v`
- **Wails CLI** `go install github.com/wailsapp/wails/v2/cmd/wails@latest`
- **Google AI API key** â€“ Required for AI chat functionality. Create one for free in [Google AI Studio](https://aistudio.google.com/app/apikey). You'll be prompted to enter this key when you first use the chat feature in Step 3.
- **Windows users:** WSLÂ 2 with Ubuntu (or another supported distro); the Cursor CLI installation runs inside WSL.

### 5.2. Clone & Bootstrap

```bash
git clone https://github.com/glebkudr/shotgun_code
cd shotgun_code
go mod tidy           # backend deps
cd frontend
npm install           # Vue deps
cd ..
```

### 5.3. Run in Dev Mode

```bash
wails dev
```

Hotâ€‘reloads Vue; restart the command for Go code changes.

### 5.4. Build a Release

```bash
wails build           # binaries land in build/bin/
```

---

## 6. Quickâ€‘Start Workflow

1. Run `wails dev`. The app window will open.
2. **Step 1: Prepare Context**
    - Click "Select Project Folder" and choose your repository root.
    - In the left pane (`LeftSidebar`), expand folders and un-tick any items you wish to exclude from the context.
    - The project context will be generated automatically.
3. **Step 2: Compose Prompt**
    - The view will switch to Step 2.
    - Enter your instructions for the LLM in the "Your task for AI" textarea. The final prompt will be assembled automatically.
4. **Step 3: Chat with AI**
    - The view will switch to Step 3.
    - Enter your Google AI API Key and save it (you can generate one in Google AI Studio).
    - The initial prompt from Step 2 will be sent automatically. You can continue the conversation to refine the result.
    - Once you are satisfied with the AI's response, click "Use Last Response & Proceed".
5. **Step 4: Execute with Cursor CLI**
    - The view will switch to Step 4.
    - Shotgun checks for the Cursor CLI (`cursor-agent`) and will offer to install it automatically if it is missing (requires WSL on Windows).
    - Click "Execute with Final Prompt" to apply the changes to your project using Cursor.
6. You can navigate between completed steps using the top `HorizontalStepper` or the `LeftSidebar` step list.

---

## 7. Shotgun Output Anatomy

```text
app/
â”œâ”€â”€ main.go
â”œâ”€â”€ app.go
â””â”€â”€ frontend/
    â”œâ”€â”€ App.vue
    â””â”€â”€ components/
        â””â”€â”€ FileTree.vue (example)

<file path="main.go">
package main
...
</file>

<file path="frontend/components/FileTree.vue">
<template>
...
</template>
</file>
```

- **Tree View** â€“ quick visual map for you & the LLM.
- **XML-like File Blocks** â€“ <file path="path/to/file">...</file> for easy parsing by models.

---

## 8. Best Practices

- **Trim the noise** â€“ exclude lock files, vendored libs, generated assets.
  Less tokens â†’ cheaper & more accurate completions.
- **Ask for diffs, not whole files** â€“ keeps responses concise.
- **Iterate** â€“ generate â†’ ask â†’ patch â†’ reâ€‘generate if needed.
- **Watch token limits** â€“ even millionâ€‘token models have practical caps.
  Use Shotgun scopes (root folder vs subfolder) to stay under budget.

---

## 9. Troubleshooting

| Symptom                     | Fix                                                            |
| --------------------------- | -------------------------------------------------------------- |
| `wails: command not found`  | Ensure `$GOROOT/bin` or `$HOME/go/bin` is on `PATH`.           |
| Blank window on `wails dev` | Check Node version & reinstall frontend deps.                  |
| Output too large            | Split Shotgun runs by subdirectory; or exclude binaries/tests. |

---

## 10. Roadmap

- âœ… **Step 1: Prepare Context**  
  Basic ability to select a project, exclude items, and generate a structured text context.

- âœ… **Step 2: Compose Prompt**

  - âœ… **Watchman to hot-reload TreeView**
  - âœ… **Custom rules**

- âœ… **Step 3: Chat with AI**
  - âœ… Implement a streaming chat interface with Google Gemini.
  - âœ… Manage API Key.
  - âœ… Use chat output as the final prompt for Step 4.

- â˜ **Step 4: Execute with Cursor**
  - â˜ CLI version for headless pipelines
  - **Watch token limits** â€“ even million-token models have practical caps. Use Shotgun scopes (root folder vs subfolder) to stay under budget.

---

## 11. Contributing

PRs and issues are welcome!
Please format Go code with `go fmt` and follow Vue 3 style guidelines.

---

## 12. License

Custom MIT-like â€“ see `LICENSE.md` file.

---

Shotgun â€“ load, aim, blast your code straight into the mind of an LLM.
Iterate faster. Ship better.
